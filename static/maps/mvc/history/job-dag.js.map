{"version":3,"sources":["mvc/history/job-dag.js"],"names":["define","GRAPH","addLogging","_super","Graph","JobDAG","options","self","this","_jobsData","_historyContentsMap","_toolMap","noOutputJobs","filteredErroredJobs","filteredSetMetadata","_","omit","dataKeys","prototype","constructor","init","excludeSetMetadata","defaults","_initFilters","call","filters","push","jobData","job","tool_id","id","excludeErroredJobs","state","isArray","concat","debug","length","data","preprocessHistoryContents","has","historyContents","preprocessTools","tools","preprocessJobs","jobs","_filterJobs","read","content","forEach","i","each","clone","tool","sort","info","create_time","preprocessJob","noInputJobs","a","b","inputs","index","input","_processInputs","size","outputs","_processOutputs","inputMap","nameInJob","_validateInputOutput","name","inputOutput","src","outputMap","output","_outputIdToJobMap","filter","j","_filterJob","createVertex","jobsData","targetId","sourceId","dataset","inputId","createJobLessVertex","JOBLESS_ID_MANGLER","createEdge","directed","JSON","stringify","aCreateTime","contentId","jobsDataMap","mangledId","weakComponentGraphArray","dag","weakComponents","map","component","vertices","bCreateTime","_jobsDataMap"],"mappings":"aAAAA,QAAQ,cAAe,qBAAsB,SAASC,EAAOC,GAIzD,IAAIC,EAASF,EAAMG,MAKfC,EAAS,SAASC,GAClBA,EAAUA,MACV,IAAIC,EAAOC,KAAXD,EAAIA,WAOJA,EAAKE,aAFLF,EAAAG,uBACAH,EAAAI,YAEAJ,EAAKG,qBACLH,EAAKI,eAILJ,EAAKK,gBAALL,EAAKK,uBAILL,EAAKM,uBADLN,EAAKO,UAAAA,OAAL,kBAAA,SACAP,EAAKM,KAIDN,GAFJA,EACAJ,EAAAA,KAAAG,EAEIC,EACAQ,UAzBRA,EAAAC,KAAAV,EAAAC,EAAAU,YAqWA,OAxUAZ,EAAOa,UAAY,IAAIjB,EAAMG,MAG7BC,EAAAa,UAAAC,YAAAd,EAGAH,EAAAG,GAEAA,EAAOa,UAAUE,KAAO,SAAed,GAGnCA,EAAIC,MAEAc,IAAAA,EAAAA,KAKJ,OANmCd,EAAnCD,QAAAS,EAAAO,SAAAhB,GAGAC,oBAAoBgB,IAEpBpB,EAAAA,QAAOe,EAAUE,eATrBjB,EAAAe,UAAAE,KAAAI,KAAAjB,EAAAD,GAUWC,GAKPF,EAAAa,UACIO,aADJ,WAAA,IAAIlB,EAAOC,KAGPD,KA6BJ,OA3BIkB,EAAAA,QAAaJ,qBACTd,EAAAO,uBACIW,EAAAC,KAAA,SAAAC,GACH,MAAA,qBAAAA,EAAAC,IAAAC,UAHLtB,EAAAO,oBAAAY,KAAAC,EAAAC,IAAAE,KAOH,MAIGL,EAAAA,QAAaM,qBACTxB,EAAAM,uBACIY,EAAAC,KAAA,SAAAC,GACH,MAAA,UAAAA,EAAAC,IAAAI,QAHLzB,EAAAM,oBAAAa,KAAAC,EAAAC,IAAAE,KAOH,MAOAf,EAAAkB,QAAA1B,EAAAD,QAAAmB,WACDlB,EAAWkB,EAAAS,OAAgBT,EAAAA,QAA3BA,UAhCJlB,EAAA4B,MAAA,eAAAV,EAAAW,QAiCWX,GAMPpB,EAAAa,UACUmB,KAAM,SAAZA,GAIA,IAAA9B,EAAAC,KACA,OACAD,EAAAA,IACK+B,EAAAA,oBANLvB,EAAEwB,IAAIF,EAAM,SAUZtB,EAAAwB,IAAAF,EAAA,UAIJ9B,EAlBJ+B,0BAAAD,EAAAG,qBAWaC,gBAAgBJ,EAAKK,WAUlCC,eAAAN,EAAAO,UAKQrC,EAAAA,YAAJA,EAAAsC,eACKnC,GAEL8B,EAAAA,UAAwBM,KAAAtB,KAASuB,KAAAA,IAIpC1C,EAXDa,UAAAoB,0BAAA,SACIE,GAaJnC,KAAOa,KAAAA,sBACH,IAAAX,EAAUC,KAMT,OALDD,EAAIA,uBATJiC,EAAgBQ,QAAQ,SAASD,EAASE,GAYxCC,EAAKR,oBAAOK,EAAmBjB,IAAAf,EAAAoC,MAAAJ,KAAjCxC,GAMJF,EAAAa,UAAAuB,gBAAA,SAAAC,GACArC,KAAOa,KAAAA,oBACH,IAAAX,EAAUC,KAMT,OALDD,EAAIA,YATJQ,EAAEmC,KAAKR,EAAO,SAASU,EAAMtB,GAY7BvB,EAAKE,SAAYF,GAAK8C,EAALF,MAAAC,KAAjB7C,GAMHF,EAXDa,UAAAyB,eAAA,SAAAC,GACIpC,KAAK8C,KAAK,mBAYd,IAAA/C,EAAAC,KAQS,OAPTH,EAAOa,qBAECX,EAAAE,UAAM8C,EAAFF,KAAkBE,GAAAA,IAAtB,SAAmC3B,GAC/B,OAAArB,EAAAiD,cAAAzC,EAAAoC,MAAAvB,MAIHrB,GAIRF,EAXDa,UAAAmC,KAAA,SAAAT,GAqBQrC,OAAAA,EAAKkD,KApBT,SAAmBC,EAAGC,GAY1B,OAAAD,EAAAH,YAAAI,EAAAJ,YACiBC,EAETjD,EAAAA,YAAJoD,EAAAJ,aACgB3B,EAERgC,KAMJrD,EAAAA,UAAKK,cAAkBgB,SAAvBA,EAAAiC,GATJ,IAAItD,EAAOC,KAYXmB,GAAepB,IAAKI,GAchBmD,OAZJnC,EAAAiC,OAAArD,EAAAwD,eAAAnC,GACA,IAAAb,EAAAiD,KAAOrC,EAAPiC,SAjBJrD,EAAAkD,YAAA/B,KAAAE,EAAAE,IAoBAH,EAAAsC,QAAA1D,EAAA2D,gBAAAtC,GAVoC,IAA5Bb,EAAEiD,KAAKrC,EAAQsC,UAYhB/C,EAAAA,aAAU6C,KAAjBnC,EAAkCE,IAC9BH,EAEIwC,KAAW5D,EAFfI,SAAAiB,EAAAC,SAKIiC,GAKAA,EAAAA,UAAMf,eAAerC,SAArBkB,GACAuC,IAAAA,EAAAA,KARJP,EAAAhC,EAAAgC,OAUAO,KAmBC,OAjCLpD,EAAAmC,KAAAU,EAAA,SAAAE,EAAAM,IAKQN,EAAQ/C,EAAEoC,MAAM5C,EAAK8D,qBAAqBP,KAYlDQ,KAAAF,EAUKN,EAAAf,QAAAxC,EAAAG,oBAAAoD,EAAAhC,IACGqC,EAACI,EAAYC,IAAOD,IAKvBJ,GAdL9D,EAAOa,UAAUmD,qBAAuB,SAoBxChE,GACI,IACI4D,EAAUrC,GACV6C,MAAAA,IAAAA,MACGR,8BACHS,KAAS3D,UAAQR,IAGjBmE,IAAAA,EAAO3B,KAAerC,QAALH,EAAKG,IACtB+D,MAAAA,IAAUC,MAlBN,gCAoBJnE,KAAKoE,UAAAA,IAXb,OAAAJ,GAmBIlE,EAAAa,UAAYT,gBAAiB,SAAemB,GACxC,IAAArB,EAAOA,KADX0D,EAAArC,EAAAqC,QAFJQ,KAoBY,OAjCR1D,EAAEmC,KAAKe,EAAS,SAASS,EAAQN,IAoBrCM,EAAA3D,EAAAoC,MAAA5C,EAAA8D,qBAAAK,KAlBeJ,KAAOF,EAqBlBM,EAAA3B,QAAAxC,EAAAG,oBAAAgE,EAAA5C,IACIvB,EAAOmE,EAAX5C,IAAA4C,EAEInE,EAAKA,kBAAgBiB,EAAhBM,IAA2BH,EAAhCG,KAOI2C,GAIXpE,EAfDa,UAAA2B,YAAA,WARI,IAAItC,EAAOC,KAyBf,OAAAD,EAAAE,UAAAmE,OAAA,SAAAC,EAAA5B,GAvBQ,OAAO1C,EAAKuE,WAAWD,EAAG5B,MAMlC5C,EAAOa,UAAU4D,WAAa,SAAoBnD,EAASkC,GA2BnDtD,IAAAA,IADAA,EAAIuB,KACCK,EAAAA,EAAMc,EAAX1C,EAAqBoB,QAArBS,OAAAa,IACA1C,IAAKwE,EAAAA,QAAajD,GAAlBN,KAAsBG,EAAtBA,GAOI,OAVRpB,EAAA4B,MAKO6C,SACCC,EAAWtD,IAAAA,GACRA,wCACHpB,EAAAkB,QAAAwB,KAEA,EAGIiC,OAAAA,GAMAC,EAAAA,UAAAA,YAASC,SAAAA,GADsC,IAAA7E,EAAnDC,KA+CC,OA5CJD,EAdD4B,MAAA,gBAPJpB,EAAEmC,KAAK8B,EAAU,SAASrD,GAyB1BpB,IAAK4B,EACDR,EAAAC,IAAAE,GAGJvB,EAAOA,MAAP,KAAAuB,EAAAH,GAlCJpB,EAAAwE,aAAAjD,EAAAH,KAqCAZ,EAAAmC,KAAA8B,EAAA,SAAArD,GACOT,IAAAA,EAAUmE,EAAAA,IAAAA,GAGbtE,EAAAmC,KAAAvB,EAAAiC,OAAA,SAAAE,EAAAsB,GAEIE,IAAAA,EAAAA,EAAqBX,kBAAzBS,GAEYL,IA3BAG,EAoBhB3E,EAAA8E,oBAAAD,GApByCd,MAqCjC/D,EAAAgF,WAAAL,EAAAD,EAAA1E,EAAAiF,UACAL,QAAAC,QAUQ7E,EAAA4B,MACH,gBACDsD,KAAAC,UAAIC,EAAAA,qBAA2B,KAAA,OAE9BpF,GAIRF,EApBDa,UAAAmE,oBAAA,SAFJO,GA2BI,IACIC,EADmB,QACWlE,EACjC,OAFDnB,KAAAuE,aAGAe,EALJtF,KAAAE,oBAAAkF,KAzBAvF,EAAOa,UAAU6E,wBAA0B,WACvC,IAAIC,EAAMxF,KACV,OAAOA,KAAKyF,iBAAiBC,IAAI,SAASC,GAmBtC,OAfAA,EAAUC,SAAS/C,KAAK,SAAmBK,EAAGC,GAC1C,IAAIgC,EAAcjC,EAAErB,KAAKT,IACf8B,EAAErB,KAAKT,IAAI2B,YACXG,EAAErB,KAAKkB,YACb8C,EAAc1C,EAAEtB,KAAKT,IACf+B,EAAEtB,KAAKT,IAAI2B,YACXI,EAAEtB,KAAKkB,YACjB,OAAIoC,EAAcU,EACP,EAEPV,EAAcU,GACN,EAEL,IAEJ,IAAIjG,MAAM4F,EAAIR,SAAUW,MAIvC9F,EAAOa,UAAUoF,aAAe,WAC5B,IAAIT,KAIJ,OAHArF,KAAKC,UAAUuC,QAAQ,SAASrB,GAC5BkE,EAAYlE,EAAQC,IAAIE,IAAMH,IAE3BkE,GAIJxF","file":"../../../scripts/mvc/history/job-dag.js","sourcesContent":["define([\"utils/graph\", \"utils/add-logging\"], function(GRAPH, addLogging) {\n    \"use strict\";\n\n    // ============================================================================\n    var _super = GRAPH.Graph;\n    /** A Directed acyclic Graph built from a history's job data.\n *      Reads in job json, filters and process that json, and builds a graph\n *      using the connections between job inputs and outputs.\n */\n    var JobDAG = function(options) {\n        options = options || {};\n        var self = this;\n        //this.logger = console;\n\n        self.filters = [];\n\n        // instance vars\n        //TODO: needed?\n        self._jobsData = [];\n        self._historyContentsMap = {};\n        self._toolMap = {};\n\n        self._outputIdToJobMap = {};\n        self.noInputJobs = [];\n        self.noOutputJobs = [];\n\n        //TODO: save these?\n        self.filteredSetMetadata = [];\n        self.filteredErroredJobs = [];\n\n        self.dataKeys = [\"jobs\", \"historyContents\", \"tools\"];\n        _super.call(\n            self,\n            true,\n            _.pick(options, self.dataKeys),\n            _.omit(options, self.dataKeys)\n        );\n    };\n    JobDAG.prototype = new GRAPH.Graph();\n    JobDAG.prototype.constructor = JobDAG;\n\n    // add logging ability - turn off/on using the this.logger statement above\n    addLogging(JobDAG);\n\n    // ----------------------------------------------------------------------------\n    /** process jobs, options, filters, and any history data, then create the graph */\n    JobDAG.prototype.init = function _init(options) {\n        options = options || {};\n\n        var self = this;\n        self.options = _.defaults(options, {\n            excludeSetMetadata: false\n        });\n        self.filters = self._initFilters();\n\n        _super.prototype.init.call(self, options);\n        return self;\n    };\n\n    /** add job filters based on options */\n    JobDAG.prototype._initFilters = function __initFilters() {\n        var self = this,\n            filters = [];\n\n        if (self.options.excludeSetMetadata) {\n            self.filteredSetMetadata = [];\n            filters.push(function filterSetMetadata(jobData) {\n                if (jobData.job.tool_id !== \"__SET_METADATA__\") {\n                    return true;\n                }\n                self.filteredSetMetadata.push(jobData.job.id);\n                return false;\n            });\n        }\n\n        if (self.options.excludeErroredJobs) {\n            self.filteredErroredJobs = [];\n            filters.push(function filterErrored(jobData) {\n                if (jobData.job.state !== \"error\") {\n                    return true;\n                }\n                self.filteredErroredJobs.push(jobData.job.id);\n                return false;\n            });\n        }\n\n        // all outputs deleted\n        // all outputs hidden\n\n        if (_.isArray(self.options.filters)) {\n            filters = filters.concat(self.options.filters);\n        }\n        self.debug(\"filters len:\", filters.length);\n        return filters;\n    };\n\n    /**  */\n    JobDAG.prototype.read = function _read(data) {\n        var self = this;\n        if (\n            _.has(data, \"historyContents\") &&\n            _.has(data, \"jobs\") &&\n            _.has(data, \"tools\")\n        ) {\n            // a job dag is composed of these three elements:\n            //  clone the 3 data sources into the DAG, processing the jobs finally using the history and tools\n            self\n                .preprocessHistoryContents(data.historyContents || [])\n                .preprocessTools(data.tools || {})\n                .preprocessJobs(data.jobs || []);\n\n            // filter jobs and create the vertices and edges of the job DAG\n            self.createGraph(self._filterJobs());\n            return self;\n        }\n        return _super.prototype.read.call(this, data);\n    };\n\n    /**  */\n    JobDAG.prototype.preprocessHistoryContents = function _preprocessHistoryContents(\n        historyContents\n    ) {\n        this.info(\"processing history\");\n        var self = this;\n        self._historyContentsMap = {};\n\n        historyContents.forEach(function(content, i) {\n            self._historyContentsMap[content.id] = _.clone(content);\n        });\n        return self;\n    };\n\n    /**  */\n    JobDAG.prototype.preprocessTools = function _preprocessTools(tools) {\n        this.info(\"processing tools\");\n        var self = this;\n        self._toolMap = {};\n\n        _.each(tools, function(tool, id) {\n            self._toolMap[id] = _.clone(tool);\n        });\n        return self;\n    };\n\n    /** sort the cloned jobs, decorate with tool and history contents info, and store in prop array */\n    JobDAG.prototype.preprocessJobs = function _preprocessJobs(jobs) {\n        this.info(\"processing jobs\");\n        var self = this;\n        self._outputIdToJobMap = {};\n\n        self._jobsData = self.sort(jobs).map(function(job) {\n            return self.preprocessJob(_.clone(job));\n        });\n        //console.debug( JSON.stringify( self._jobsData, null, '    ' ) );\n        //console.debug( JSON.stringify( self._outputIdToJobMap, null, '    ' ) );\n        return self;\n    };\n\n    /** sort the jobs based on update time */\n    JobDAG.prototype.sort = function _sort(jobs) {\n        function cmpCreate(a, b) {\n            if (a.create_time > b.create_time) {\n                return 1;\n            }\n            if (a.create_time < b.create_time) {\n                return -1;\n            }\n            return 0;\n        }\n        return jobs.sort(cmpCreate);\n    };\n\n    /** decorate with input/output datasets and tool */\n    JobDAG.prototype.preprocessJob = function _preprocessJob(job, index) {\n        //this.info( 'preprocessJob', job, index );\n        var self = this,\n            jobData = { job: job };\n\n        jobData.inputs = self._processInputs(job);\n        if (_.size(jobData.inputs) === 0) {\n            self.noInputJobs.push(job.id);\n        }\n        jobData.outputs = self._processOutputs(job);\n        if (_.size(jobData.outputs) === 0) {\n            self.noOutputJobs.push(job.id);\n        }\n\n        jobData.tool = self._toolMap[job.tool_id];\n\n        //self.info( '\\t jobData:', jobData );\n        return jobData;\n    };\n\n    /**\n */\n    JobDAG.prototype._processInputs = function __processInputs(job) {\n        var self = this,\n            inputs = job.inputs,\n            inputMap = {};\n        _.each(inputs, function(input, nameInJob) {\n            input = _.clone(self._validateInputOutput(input));\n            input.name = nameInJob;\n            // since this is a DAG and we're processing in order of create time,\n            //  the inputs for this job will already be listed in _outputIdToJobMap\n            //  TODO: we can possibly exploit this\n            //console.debug( 'input in _outputIdToJobMap', self._outputIdToJobMap[ input.id ] );\n            input.content = self._historyContentsMap[input.id];\n            inputMap[input.id] = input;\n        });\n        return inputMap;\n    };\n\n    /**\n */\n    JobDAG.prototype._validateInputOutput = function __validateInputOutput(\n        inputOutput\n    ) {\n        if (!inputOutput.id) {\n            throw new Error(\n                \"No id on job input/output: \",\n                JSON.stringify(inputOutput)\n            );\n        }\n        if (!inputOutput.src || inputOutput.src !== \"hda\") {\n            throw new Error(\n                \"Bad src on job input/output: \",\n                JSON.stringify(inputOutput)\n            );\n        }\n        return inputOutput;\n    };\n\n    /**\n */\n    JobDAG.prototype._processOutputs = function __processOutputs(job) {\n        var self = this,\n            outputs = job.outputs,\n            outputMap = {};\n        _.each(outputs, function(output, nameInJob) {\n            output = _.clone(self._validateInputOutput(output));\n            output.name = nameInJob;\n            // add dataset content to jobData\n            output.content = self._historyContentsMap[output.id];\n            outputMap[output.id] = output;\n\n            self._outputIdToJobMap[output.id] = job.id;\n        });\n        return outputMap;\n    };\n\n    /**  */\n    JobDAG.prototype._filterJobs = function __filterJobs() {\n        var self = this;\n        return self._jobsData.filter(function(j, i) {\n            return self._filterJob(j, i);\n        });\n    };\n\n    /**\n */\n    JobDAG.prototype._filterJob = function _filterJob(jobData, index) {\n        // apply filters after processing job allowing access to the additional data above inside the filters\n        var self = this;\n        for (var i = 0; i < self.filters.length; i++) {\n            if (!self.filters[i].call(self, jobData)) {\n                self.debug(\n                    \"\\t job\",\n                    jobData.job.id,\n                    \" has been filtered out by function:\\n\",\n                    self.filters[i]\n                );\n                return false;\n            }\n        }\n        return true;\n    };\n\n    /** Walk all the jobs (vertices), attempting to find connections\n *  between datasets used as both inputs and outputs (edges)\n */\n    JobDAG.prototype.createGraph = function _createGraph(jobsData) {\n        var self = this;\n        self.debug(\"connections:\");\n        //console.debug( jobsData );\n\n        _.each(jobsData, function(jobData) {\n            var id = jobData.job.id;\n            self.debug(\"\\t\", id, jobData);\n            self.createVertex(id, jobData);\n        });\n        _.each(jobsData, function(jobData) {\n            var targetId = jobData.job.id;\n            _.each(jobData.inputs, function(input, inputId) {\n                //console.debug( '\\t\\t target input:', inputId, input );\n                var sourceId = self._outputIdToJobMap[inputId];\n                //console.debug( '\\t\\t source job id:', sourceId );\n                if (!sourceId) {\n                    var joblessVertex = self.createJobLessVertex(inputId);\n                    sourceId = joblessVertex.name;\n                }\n                //TODO:?? no checking here whether sourceId is actually in the vertex map\n                //console.debug( '\\t\\t creating edge, source:', sourceId, self.vertices[ sourceId ] );\n                //console.debug( '\\t\\t creating edge, target:', targetId, self.vertices[ targetId ] );\n                self.createEdge(sourceId, targetId, self.directed, {\n                    dataset: inputId\n                });\n            });\n        });\n        //console.debug( self.toVerticesAndEdges().edges );\n\n        self.debug(\n            \"final graph: \",\n            JSON.stringify(self.toVerticesAndEdges(), null, \"  \")\n        );\n        return self;\n    };\n\n    /** Return a 'mangled' version of history contents id to prevent contents <-> job id collision */\n    JobDAG.prototype.createJobLessVertex = function _createJobLessVertex(\n        contentId\n    ) {\n        // currently, copied contents are the only history contents without jobs (that I know of)\n        //note: following needed to prevent id collision btwn content and jobs in vertex map\n        var JOBLESS_ID_MANGLER = \"copy-\",\n            mangledId = JOBLESS_ID_MANGLER + contentId;\n        return this.createVertex(\n            mangledId,\n            this._historyContentsMap[contentId]\n        );\n    };\n\n    /** Override to re-sort (ugh) jobs in each component by update time */\n    JobDAG.prototype.weakComponentGraphArray = function() {\n        var dag = this;\n        return this.weakComponents().map(function(component) {\n            //TODO: this seems to belong above (in sort) - why isn't it preserved?\n            // note: using create_time (as opposed to update_time)\n            //  since update_time for jobless/copied datasets is changes more often\n            component.vertices.sort(function cmpCreate(a, b) {\n                var aCreateTime = a.data.job\n                        ? a.data.job.create_time\n                        : a.data.create_time,\n                    bCreateTime = b.data.job\n                        ? b.data.job.create_time\n                        : b.data.create_time;\n                if (aCreateTime > bCreateTime) {\n                    return 1;\n                }\n                if (aCreateTime < bCreateTime) {\n                    return -1;\n                }\n                return 0;\n            });\n            return new Graph(dag.directed, component);\n        });\n    };\n\n    JobDAG.prototype._jobsDataMap = function() {\n        var jobsDataMap = {};\n        this._jobsData.forEach(function(jobData) {\n            jobsDataMap[jobData.job.id] = jobData;\n        });\n        return jobsDataMap;\n    };\n\n    // ============================================================================\n    return JobDAG;\n});\n"]}